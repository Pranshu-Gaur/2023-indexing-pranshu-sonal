{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scann\n",
        "!pip install faiss-gpu\n",
        "import faiss\n",
        "import scann"
      ],
      "metadata": {
        "id": "6zoAEAX3rzN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fKlWxV0s76Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9857ed16-70ac-44e9-f9c6-a14869add843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<faiss.swigfaiss.HNSW; proxy of <Swig Object of type 'faiss::HNSW *' at 0x7f52a4472dc0> >\n"
          ]
        }
      ],
      "source": [
        "from lsh import LSH\n",
        "from scann_algo import ScaNN_Algo\n",
        "from pq import PQ\n",
        "from hnsw import HNSW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o7TLpVpBAzSE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "import urllib.request as request\n",
        "from contextlib import closing\n",
        "\n",
        "# first we download the Sift1M dataset\n",
        "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:\n",
        "    with open('sift.tar.gz', 'wb') as f:\n",
        "        shutil.copyfileobj(r, f)\n",
        "import tarfile\n",
        "\n",
        "# the download leaves us with a tar.gz file, we unzip it\n",
        "tar = tarfile.open('sift.tar.gz', \"r:gz\")\n",
        "tar.extractall()\n",
        "def read_fvecs(fp):\n",
        "    a = np.fromfile(fp, dtype='int32')\n",
        "    d = a[0]\n",
        "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')\n",
        "\n",
        "# 1M samples\n",
        "xb = read_fvecs('./sift/sift_base.fvecs')\n",
        "# queries\n",
        "xq = read_fvecs('./sift/sift_query.fvecs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sb-x0XtQBBUk"
      },
      "outputs": [],
      "source": [
        "points = xb\n",
        "queries = points[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UXDk5ZBwjZDK"
      },
      "outputs": [],
      "source": [
        "Algorithms = []\n",
        "Algorithms.append(PQ)\n",
        "Algorithms.append(LSH)\n",
        "Algorithms.append(ScaNN_Algo)\n",
        "Algorithms.append(HNSW)\n",
        "Algorithms.append(PQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShH5Nqt1iwNS"
      },
      "outputs": [],
      "source": [
        "Algo_idx = int(input(\"Please select any Algorithm: \\n 1 - Product Quantization \\n 2 - Locality Sensitive Hashing \\n 3 - Scalable Nearest Neighbours \\n 4 - Hierarchical Navigable Small Worlds \\n 5 - Optimized Product Quantization \\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFD-ouFBjrZN"
      },
      "outputs": [],
      "source": [
        "Algorithms[Algo_idx-1](points,queries)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
